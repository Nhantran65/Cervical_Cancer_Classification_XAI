{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n",
      "12.1\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # Kiểm tra phiên bản PyTorch\n",
    "print(torch.cuda.is_available())  # Kiểm tra xem PyTorch có nhận GPU không\n",
    "print(torch.version.cuda)  # Kiểm tra phiên bản CUDA mà PyTorch đang sử dụng\n",
    "print(torch.cuda.get_device_name(0))  # Kiểm tra tên GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_path = './Multi Cancer/Cervical Cancer'\n",
    "cervix_categories = ['cervix_dyk', 'cervix_koc', 'cervix_mep', 'cervix_pab', 'cervix_sfi']\n",
    "\n",
    "# Load dataset file paths and labels\n",
    "filepaths, labels = [], []\n",
    "for label, category in enumerate(cervix_categories):\n",
    "    category_path = os.path.join(dataset_path, category)\n",
    "    for file in os.listdir(category_path):\n",
    "        filepaths.append(os.path.join(category_path, file))\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tranh\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tranh\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Custom dataset class\n",
    "class CervicalCancerDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['filepath']\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)  # Convert to PIL Image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "dataloaders = {\n",
    "    'train': DataLoader(CervicalCancerDataset(train_df, transform), batch_size=batch_size, shuffle=True),\n",
    "    'valid': DataLoader(CervicalCancerDataset(valid_df, transform), batch_size=batch_size, shuffle=False),\n",
    "    'test': DataLoader(CervicalCancerDataset(test_df, transform), batch_size=batch_size, shuffle=False)\n",
    "}\n",
    "\n",
    "# Define model\n",
    "class CervicalCancerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CervicalCancerModel, self).__init__()\n",
    "        self.base_model = models.resnet101(pretrained=True)\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(self.base_model.fc.in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, len(cervix_categories))\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CervicalCancerModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adamax(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tranh\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tranh\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class CervicalCancerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CervicalCancerModel, self).__init__()\n",
    "        self.base_model = models.resnet101(pretrained=True)\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(self.base_model.fc.in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, len(cervix_categories))\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CervicalCancerModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adamax(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 1/10: 100%|██████████| 547/547 [02:25<00:00,  3.76it/s, accuracy=tensor(0.8681, device='cuda:0', dtype=torch.float64), loss=0.404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Loss: 0.4040 Acc: 0.8681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID Epoch 1/10: 100%|██████████| 118/118 [00:37<00:00,  3.13it/s, accuracy=tensor(0.9323, device='cuda:0', dtype=torch.float64), loss=0.201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID Loss: 0.2007 Acc: 0.9323\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 2/10: 100%|██████████| 547/547 [02:02<00:00,  4.48it/s, accuracy=tensor(0.9263, device='cuda:0', dtype=torch.float64), loss=0.215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Loss: 0.2148 Acc: 0.9263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID Epoch 2/10: 100%|██████████| 118/118 [00:25<00:00,  4.58it/s, accuracy=tensor(0.9629, device='cuda:0', dtype=torch.float64), loss=0.123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID Loss: 0.1228 Acc: 0.9629\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 3/10: 100%|██████████| 547/547 [02:42<00:00,  3.36it/s, accuracy=tensor(0.9431, device='cuda:0', dtype=torch.float64), loss=0.163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Loss: 0.1632 Acc: 0.9431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID Epoch 3/10: 100%|██████████| 118/118 [00:32<00:00,  3.60it/s, accuracy=tensor(0.9709, device='cuda:0', dtype=torch.float64), loss=0.096] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID Loss: 0.0960 Acc: 0.9709\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 4/10: 100%|██████████| 547/547 [02:03<00:00,  4.42it/s, accuracy=tensor(0.9533, device='cuda:0', dtype=torch.float64), loss=0.133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Loss: 0.1328 Acc: 0.9533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID Epoch 4/10: 100%|██████████| 118/118 [00:31<00:00,  3.78it/s, accuracy=tensor(0.9813, device='cuda:0', dtype=torch.float64), loss=0.0722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID Loss: 0.0722 Acc: 0.9813\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 5/10: 100%|██████████| 547/547 [02:32<00:00,  3.59it/s, accuracy=tensor(0.9612, device='cuda:0', dtype=torch.float64), loss=0.112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Loss: 0.1119 Acc: 0.9612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID Epoch 5/10: 100%|██████████| 118/118 [00:26<00:00,  4.49it/s, accuracy=tensor(0.9832, device='cuda:0', dtype=torch.float64), loss=0.0638]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID Loss: 0.0638 Acc: 0.9832\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 6/10: 100%|██████████| 547/547 [02:29<00:00,  3.65it/s, accuracy=tensor(0.9686, device='cuda:0', dtype=torch.float64), loss=0.0951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Loss: 0.0951 Acc: 0.9686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID Epoch 6/10: 100%|██████████| 118/118 [00:25<00:00,  4.56it/s, accuracy=tensor(0.9880, device='cuda:0', dtype=torch.float64), loss=0.0469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID Loss: 0.0469 Acc: 0.9880\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 7/10: 100%|██████████| 547/547 [02:15<00:00,  4.03it/s, accuracy=tensor(0.9721, device='cuda:0', dtype=torch.float64), loss=0.0833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Loss: 0.0833 Acc: 0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID Epoch 7/10: 100%|██████████| 118/118 [00:25<00:00,  4.58it/s, accuracy=tensor(0.9899, device='cuda:0', dtype=torch.float64), loss=0.0386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID Loss: 0.0386 Acc: 0.9899\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 8/10: 100%|██████████| 547/547 [02:04<00:00,  4.41it/s, accuracy=tensor(0.9793, device='cuda:0', dtype=torch.float64), loss=0.0639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Loss: 0.0639 Acc: 0.9793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID Epoch 8/10: 100%|██████████| 118/118 [00:25<00:00,  4.57it/s, accuracy=tensor(0.9917, device='cuda:0', dtype=torch.float64), loss=0.0303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID Loss: 0.0303 Acc: 0.9917\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 9/10: 100%|██████████| 547/547 [02:14<00:00,  4.05it/s, accuracy=tensor(0.9792, device='cuda:0', dtype=torch.float64), loss=0.0622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Loss: 0.0622 Acc: 0.9792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID Epoch 9/10: 100%|██████████| 118/118 [00:25<00:00,  4.54it/s, accuracy=tensor(0.9952, device='cuda:0', dtype=torch.float64), loss=0.023] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID Loss: 0.0230 Acc: 0.9952\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch 10/10: 100%|██████████| 547/547 [02:23<00:00,  3.80it/s, accuracy=tensor(0.9813, device='cuda:0', dtype=torch.float64), loss=0.056] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Loss: 0.0560 Acc: 0.9813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID Epoch 10/10: 100%|██████████| 118/118 [00:25<00:00,  4.56it/s, accuracy=tensor(0.9965, device='cuda:0', dtype=torch.float64), loss=0.0188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID Loss: 0.0188 Acc: 0.9965\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training function\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            loop = tqdm(dataloaders[phase], desc=f'{phase.upper()} Epoch {epoch+1}/{num_epochs}', leave=True)\n",
    "            for inputs, labels in loop:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                correct += torch.sum(preds == labels.data)\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                loop.set_postfix(loss=running_loss/total, accuracy=correct.double()/total)\n",
    "            \n",
    "            epoch_loss = running_loss / total\n",
    "            epoch_acc = correct.double() / total\n",
    "            print(f'{phase.upper()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "train_model(model, dataloaders, criterion, optimizer)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"cervical_cancer_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
